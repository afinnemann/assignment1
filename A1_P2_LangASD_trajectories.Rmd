---
title: "Assignment 1 - Language Development in ASD - part 2"
author: "Riccardo Fusaroli"
date: "July 7, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/cogsci/EM3/Assignment I/assignment1")
library(tidyverse)
library(stringr)
library(lmerTest)
library(MuMIn)

da <- read.csv("autism_data.csv", sep = ";")
```

# Language development in Autism Spectrum Disorder (ASD)

Background: Autism Spectrum Disorder is often related to language impairment. However, this phenomenon has not been empirically traced in detail: i) relying on actual naturalistic language production, ii) over extended periods of time. We therefore videotaped circa 30 kids with ASD and circa 30 comparison kids (matched by linguistic performance at visit 1) for ca. 30 minutes of naturalistic interactions with a parent. We repeated the data collection 6 times per kid, with 4 months between each visit. We transcribed the data and counted: 
i) the amount of words that each kid uses in each video. Same for the parent.
ii) the amount of unique words that each kid uses in each video. Same for the parent.
iii) the amount of morphemes per utterance (Mean Length of Utterance) displayed by each child in each video. Same for the parent. 

This data is in the file you prepared in the previous class. 

NB. A few children have been excluded from your datasets. We will be using them next week to evaluate how good your models are in assessing the linguistic development in new participants.

We then want to test the language trajectory of child and parent over time.

This Markdown is structured in the following way:

1. The exercises: read them carefully. Under each exercise you will have to write your answers, once you have written and run the code. This is the part that you have to directly send to the teachers.
2. An (optional) guided template full of hints for writing the code to solve the exercises. Fill in the code and the paragraphs as required. Then report your results under the exercise part.
3. In exercise 4 you will be asked to create the best possible model of language development in TD and ASD children, picking and choosing whatever additional variables you want from the dataset. Next time, the models produced by the different groups will compete against each other to see who can produce the best model, so choose carefully!

You will have to have a github repository for the code and send the answers to Celine and Riccardo without code (but a link to your github repository). This way we can check your code, but you are also forced to figure out how to report your analyses :-)

N.B. The following lines are a summary of the questions to be answered, the step-by-step instructions and tips are below.

## Exercise 1) Preliminary Data Exploration

Describe the participant samples in the dataset (e.g. by diagnosis, age, etc.). Do you think the two groups are well balanced? If not, what do you think was the reason?

```{R}
#participants are analyzed at their first visit
lm_da <- da %>% 
  filter(VISIT == 1 ) 

summary(lm(Age ~  Diagnosis, data = lm_da)) #significant age difference

summary(glm(Gender ~ Diagnosis, data = lm_da, family = "binomial")) #no significant differences between

summary(lm(VerbalIQ2 ~Diagnosis,data = lm_da)) #initial verbal IQ isn't significantly different


#There is a significant age difference, but their verbal IQ is matched.

```

### Exercise 2) Children learning language: the effects of time and ASD
Describe linguistic development in TD and ASD children in terms of Mean Length of Utterance (MLU)?
```{R}


random_effect_only <- lmer(CHI_MLU ~ 1 +(1+VISIT|SUBJ), data = da)

visit_model <- lmer(CHI_MLU ~VISIT + (1+VISIT|SUBJ),da)
visit_diag <- lmer(CHI_MLU ~VISIT + Diagnosis + (1+VISIT|SUBJ),da)
diag_visit_interact <- lmer(CHI_MLU ~ VISIT * Diagnosis + (1 +VISIT|SUBJ), data = da)

anova( random_effect_only,visit_model, visit_diag, diag_visit_interact)
#interaction model is significantly better than the rest. Pretty drop in AIC and nice Chisquare value.

#comparing R2
r.squaredGLMM(visit_model)
r.squaredGLMM(visit_diag)
r.squaredGLMM( diag_visit_interact)
#Interaction model outperforms other



summary(diag_visit_interact)
#Children without ASD's MLU increases per trial 0.25 MORE than children with ASD


#cool plots
#extracting all coefficients
chi_coef <- coef(diag_visit_interact)

#selecting the random intercepts and slopes
chi_coef_df <- data.frame(chi_coef$SUBJ[1], chi_coef$SUBJ[2])

#adding subject columns
chi_coef_df$SUBJ <- levels(diag_visit_interact@flist$SUBJ)

#extracting information about subjects and diagnoses
diag <- data.frame(da$SUBJ,da$Diagnosis) %>% 
  rename(SUBJ = da.SUBJ)

#using merge to add a column with diagnosis information
chi_coef_df2 <- merge(diag, chi_coef_df, by = "SUBJ") %>% 
  filter(!duplicated(SUBJ))

#plotting trend lines over time for asd and td
da %>% 
  ggplot(aes(VISIT, CHI_MLU, color = Diagnosis)) +
  geom_point() +
  geom_smooth(size = 3)

#plotting individual for children over trials, as well as interaction coefficient.
da %>% 
  ggplot(aes(VISIT, CHI_MLU, color = Diagnosis)) +
  geom_point() +
  geom_abline(aes(intercept = X.Intercept., slope = VISIT, color = da.Diagnosis), data = chi_coef_df2)+
  #plotting interaction, slope = 0.253
  geom_abline(slope = 0.253, intercept = 0, color = "dark green", size = 3)

#There seem to be 4 exceptional autists
#Interaction line shows difference between diagnosis groups(?) over time.

```
We used R (R Core Team (2017)), and lme4 (Bates, Maechler, Bolker & Walker, 2015), MuMIn (Barton, 2016), and lmerTest (Kuznetsova, Brockhoff & Christensen, 2016) to perform a linear mixed effects analysis of the relationship between childrens' Mean Length of Utterances (MLU) and autism over time. As random effect was a by-subject per visit random slope and intercept. We included diagnosis, visit and a diagnosis:visit interaction-effect as our fixed effect. Using Anova we found that this model fitted data significantly better than less complex models, Chisq(1) = 34.96, p = 3.3e-09.

       Df    AIC    BIC  logLik deviance   Chisq Chi Df Pr(>Chisq)    
object  5 659.27 678.59 -324.64   649.27                              
..1     6 605.44 628.62 -296.72   593.44 55.8316      1  7.895e-14 ***
..2     7 605.42 632.47 -295.71   591.42  2.0177      1     0.1555    
..3     8 572.46 603.37 -278.23   556.46 34.9615      1  3.363e-09 ***

Furthermore we see that the fixed effects of the more complex models explains more variance. R2m = .35. For diagnose and visit model without interaction the marginal r2 values drops to .21.


The significant interaction effect bewtween visit and diagnose show's there is significant difference in the development of children's MLU. Children without autism did on average for each visit increase their MLU with 0.25 more than autists (Slope = 0.25, P(59.94) = 6.7, sd = 0.03, p = 7.68e-09).

Fixed effects:
                  Estimate Std. Error       df t value Pr(>|t|)    
(Intercept)        1.30476    0.12485 57.27000  10.451 6.88e-15 ***
VISIT              0.10044    0.02725 59.41000   3.686 0.000494 ***
DiagnosisTD       -0.21732    0.17244 57.36000  -1.260 0.212681    
VISIT:DiagnosisTD  0.25344    0.03774 59.94000   6.715 7.68e-09 ***


### Exercise 3) Child directed speech as a moving target
Describe how parental use of language changes over time in terms of MLU. What do you think is going on?
```{R}
baseline_mot <- lmer(MOT_MLU ~ 1 +(1+VISIT|SUBJ), data = da)

visit_model_mot <- lmer(MOT_MLU ~VISIT + (1+VISIT|SUBJ),da)
visit_diag_mot <- lmer(MOT_MLU ~VISIT + Diagnosis + (1+VISIT|SUBJ),da)

diag_visit_interact_mot <- lmer(MOT_MLU ~ VISIT * Diagnosis + (1 +VISIT|SUBJ), data = da)

anova(baseline_mot,visit_model_mot, visit_diag_mot, diag_visit_interact_mot)

#comparing R2
r.squaredGLMM(visit_model_mot)
r.squaredGLMM(visit_diag_mot)
r.squaredGLMM(diag_visit_interact_mot)


summary(visit_diag_mot)


#Parents differ by 0.5, and this difference is constant over time

coefs <-coef(visit_diag_mot)
coefs <- as.data.frame(coefs)
df <- data.frame(a = coefs$SUBJ[1], b = coefs$SUBJ[2])

da %>% 
  ggplot(aes(VISIT, MOT_MLU, color = Diagnosis)) +
  geom_point() +
  geom_abline(aes(intercept = X.Intercept., slope = VISIT, color = factor(VISIT)), data = df) +
  theme(legend.position="none")


#cool plots
#extracting all coefficients
mot_coef <- coef(visit_diag_mot)

#selecting the random intercepts and slopes
mot_coef_df <- data.frame(mot_coef$SUBJ[1], mot_coef$SUBJ[2])

#adding subject columns
mot_coef_df$SUBJ <- levels(visit_diag_mot@flist$SUBJ)

#extracting information about subjects and diagnoses
diag <- data.frame(da$SUBJ,da$Diagnosis) %>% 
  rename(SUBJ = da.SUBJ)

#using merge to add a column with diagnosis information
mot_coef_df2 <- merge(diag, mot_coef_df, by = "SUBJ") %>% 
  filter(!duplicated(SUBJ))

#plotting trend lines over time for asd and td
da %>% 
  ggplot(aes(VISIT, MOT_MLU, color = Diagnosis)) +
  geom_point() +
  geom_smooth(size = 3)

#plotting individual for children over trials, as well as interaction coefficient.
da %>% 
  ggplot(aes(VISIT, MOT_MLU, color = Diagnosis)) +
  geom_point() +
  geom_abline(aes(intercept = X.Intercept., slope = VISIT, color = da.Diagnosis), data = mot_coef_df2) +
  scale_y_continuous(limits = c(0,6)) +
  scale_x_continuous(limits = c(0,6))


```
We used R (R Core Team (2017)), and lme4 (Bates, Maechler, Bolker & Walker, 2015), MuMIn (Barton, 2016), and lmerTest (Kuznetsova, Brockhoff & Christensen, 2016) to perform a linear mixed effects analysis of the relationship between mothers' Mean Length of Utterances (MLU) and childrens' autism over time. 
As random effect was by-subject per visit random slopes and intercepts. We ended up with diagnosis and visit as fixed effects in our final model. Further complexities to the model, such as interaction-effects, didn't increase the marginal R2 or decreased the Akaike-Information-Criterion.


       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)    
object  5 558.66 577.98 -274.33   548.66                             
..1     6 527.44 550.62 -257.72   515.44 33.222      1  8.223e-09 ***
..2     7 512.71 539.75 -249.35   498.71 16.728      1  4.314e-05 ***
..3     8 513.48 544.39 -248.74   497.48  1.227      1      0.268    

 r.squaredGLMM(visit_diag_mot)
      R2m       R2c 
0.2258902 0.6815522 
 r.squaredGLMM(diag_visit_interact_mot)
      R2m       R2c 
0.2250557 0.6813587 


We found a significant main effect of the number of visits on mother MLU. 
(Slope = 0.12, sd = 0.0183, t(58.57) = 6.54, p = 1.65e-08) 

Furthermore, we found a main effect of diagnose: 
(Slope = 0.5, sd = 0.115, t(58.92) = 4.356, p = 5.36e-05)
Since we haven't found a significant interaction effect we can conclude that there is a constant difference over time of 0.5 MLU between mothers of the two diagnosis groups, this finding is also consistent with the pattern shown by geom_smooth in the first plot.


Fixed effects:
            Estimate Std. Error       df t value Pr(>|t|)    
(Intercept)  3.23804    0.10684 78.03000  30.308  < 2e-16 ***
VISIT        0.12026    0.01838 58.57000   6.542 1.65e-08 ***
DiagnosisTD  0.50199    0.11523 58.92000   4.356 5.36e-05 ***



### Exercise 4) Looking into "individual differences" (demographic, clinical or cognitive profiles)
The dataset contains some additional variables characterizing the kids’ cognitive and clinical profile: ADOS (autism severity), MSEL EL (Expressive Language, that is, verbal IQ, or linguistic skills at first visit as assessed by a psychologist using Mullen Scales of Early Learning), MSEL VR (Visual Reception, used as a proxy for non verbal IQ at first visit), Age, Gender, Ethnicity. Would it make sense to add any of them to your model of linguistic trajectories? Create the best possible model (the one that best explain the data, with MLU as outcome). Next time your model will be tested on new participants, and we will proclaim a winner. Describe your strategy to select the best models (how did you choose the variables to include?) and send the code to Riccardo and Celine.

```{R}
#Use PCA to find a principle component that predicts CHI_MLU

library(psych)
library(corrgram)


#checking for sufficient covariance
#the corrgram shows darker areas indicating covariance among predictors
corrgram(da2[,c(3,7:9,11:14)], col.regions = colorRampPalette(c("dodgerblue4",'dodgerblue','white', 'gold',"firebrick4")),cor.method='pearson')


cortest.bartlett(da2[,c(3,7:14)]) # yields significant result, Chisq(28) = 2626, p = 0. In other words the correlation matrix is significantly different from an identity-matrix


#Principle component analysis:
pca <- principal(da2[,c(3,7:9,11:14)], nfactors = length(7:14), scores = TRUE, rotate = "oblimin")

#Scree plot
plot(pca$values, type = "b")
#keeping 4 factors, although the first component seems to reflect most of covariance.

pc1 <- principal(da2[,c(3,7:9,11:14)], nfactors = 4, scores = TRUE, rotate = "oblimin")

#we can check out factor loadings:
print.psych(pc1, cut = 0.3, sort = TRUE) #very sensible components


#creating a dataframe to model from
pca_data <- cbind(da2, pc1$scores)

pca_model1 <- lmer(CHI_MLU ~  TC3 +(1+VISIT|SUBJ), pca_data)
pca_model2 <- lmer(CHI_MLU ~  TC3 + TC4 +(1+VISIT|SUBJ), pca_data)
pca_model3 <- lmer(CHI_MLU ~  TC3 + TC4 + TC1 +(1+VISIT|SUBJ), pca_data)
pca_model4 <- lmer(CHI_MLU ~  TC3 + TC4 + TC1 +TC2+(1+VISIT|SUBJ), pca_data)

base_pca <- lmer(CHI_MLU ~ MOT_MLU*types_CHI*VISIT + VerbalIQ2 +(1+VISIT|SUBJ), pca_data)

anova(base_pca, pca_model1, pca_model2, pca_model3, pca_model4)
#PCA models outperforms the other model (which is also qualified)

r.squaredGLMM(pca_model1)
r.squaredGLMM(pca_model2)
r.squaredGLMM(pca_model3)
r.squaredGLMM(pca_model4)
r.squaredGLMM(base_pca)

#The three PCA models are nearly equal in R2 and AIC. However from the Anova we see that the pca_model2 explains the CHI_MLU significantly better.
#final model

the_beauty <- pca_model2 <- lmer(CHI_MLU ~  TC3 + TC4 + TC1 + (1+SUBJ|VISIT), pca_data)
r.squaredGLMM(the_beauty)




```

### [OPTIONAL] Exercise 5) Comment on how the three linguistic variables measure linguistic performance (the so-called "construct validity" of the measures). Do they express the same variance?

```{R}
#we can read the predictor covariance from the factor loadings:
print.psych(pc1, cut = 0.3, sort = TRUE) 



```

### Structure of the code chunks

Basic stuff:
- Loading the libraries
- Setting the directory and loading the data
- Look at the data (which variables are there? Are they in the right format?) and describe the participants (by diagnosis)

We will try to answer three questions:

- Do children with ASD develop language differently from non-ASD children?
- Do parents speak differently to children with ASD than to non-ASD ones?
- Which variables should we use to best explain the child linguistic performance?
  
### Loading the relevant libraries

Load necessary libraries : what will you need?

- e.g. something to plot with
- e.g. mixed effects models

```{r Load Libraries}


```

### Define your working directory and load the data

- Create a new variable called locpath (localpath)
- Set it to be equal to your working directory
- Move to that directory (setwd(locpath))
- Load the data you saved last time (use read_csv(fileName))

```{r Load Data}

#getwd()
#locpath=
#setwd(locpath)
#Data =

```

### Characterize the participants (Exercise 1)

Identify relevant variables: participants demographic characteristics, diagnosis, ADOS, Verbal IQ, Non Verbal IQ, Visit, Number of words used, Number of unique words used, length of utterance in both child and parents.

Make sure the variables are in the right format.

Describe the characteristics of the two groups of participants and whether the two groups are well matched.

```{r}

```

[REPORT THE RESULTS]

## Let's test hypothesis 1: Children with ASD display a language impairment  (Exercise 2)

### Hypothesis: The child's MLU changes: i) over time, ii) according to diagnosis

Let's start with a simple mixed effects linear model

Remember to plot the data first and then to run a statistical test.
- Which variable(s) should be included as fixed factors?
- Which variable(s) should be included as random factors?

```{r}

```

How would you evaluate whether the model is a good model?

```{r}

```

Not too good, right? Let's check whether a growth curve model is better.
Remember: a growth curve model assesses whether changes in time can be described by linear, or quadratic, or cubic (or... etc.) components.
First build the different models, then compare them to see which one is better

```{r}

```

Exciting right?
Now it's time to report our results.
Remember to report:
- the estimates for each predictor (beta estimate, standard error, p-value)
- A plain word description of the results

[REPORT THE RESULTS]
Linguistic development of children MLU is affected by ... [COMPLETE]

## Let's test hypothesis 2: Parents speak equally to children with ASD and TD  (Exercise 3)

### Hypothesis: Parental MLU changes: i) over time, ii) according to diagnosis

```{r}

```

[REPORT THE RESULTS]

### Adding new variables (Exercise 4)

Your task now is to figure out how to best describe the children linguistic trajectory. The dataset contains a bunch of additional demographic, cognitive and clinical variables (e.g.verbal and non-verbal IQ). Try them out and identify the statistical models that best describes your data (that is, the children's MLU). Describe how you selected the best model and send the code to run the model to Riccardo and Celine.


```{r}





```

REPORT OF THE RESULTS